<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: program | ]]></title>
  <link href="http://zyearn.github.io/blog/categories/program/atom.xml" rel="self"/>
  <link href="http://zyearn.github.io/"/>
  <updated>2021-01-26T23:50:59+01:00</updated>
  <id>http://zyearn.github.io/</id>
  <author>
    <name><![CDATA[Jiashun Zhu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[如何生成[0, N)中的随机数]]></title>
    <link href="http://zyearn.github.io/blog/2017/01/07/how-to-generate-uniform-distribution/"/>
    <updated>2017-01-07T17:40:00+01:00</updated>
    <id>http://zyearn.github.io/blog/2017/01/07/how-to-generate-uniform-distribution</id>
    <content type="html"><![CDATA[<p>写程序的时候，经常会遇到这样的需求：已知rand函数，生成一个范围在[0, N)的随机数。
比如我们有15个球，随机选择一个，则此时N等于15。
在这个问题中，我们通常希望这个随机数是满足均匀分布（uniform distribution）的，即每个数字出现的概率是一样的。
还有一类随机数生成问题，是要求实现rand这个函数本身的，<a href="https://en.wikipedia.org/wiki/Pseudorandom_number_generator">这类问题</a>已经被广泛过，这篇文章不会讨论这类的问题。</p>

<p>之前看到的几乎所有的地方(包括我自己)都是这么写的：</p>

<pre><code>int r = rand() % N;
</code></pre>

<p>后来校招面试百度的时候，一位叫戈君的面试官无意中告诉我这么写是错的，我回来想了一想，果然是不对的。
各位读者如果以前一直都是这么写的，不妨先不要继续看下去，自己思考一下错在什么地方。</p>

<p>为了说明错在哪里，我们举一个简单的例子：
我们假设rand()的返回的最大值是9，N等于7，那么rand()返回[0,6]时，直接返回该值；如果返回[7,9]时，则返回[0,2]，我们可以看出，返回0的概率是2/10，因为rand()得到0和7都会使结果为0，同理1和2的概率也是2/10，但是[3,6]中的数概率为1/10。这显然不符合均匀分布的定义。</p>

<p>稍稍想想可以发现：问题出在了N不能整除rand()返回的范围，使得最后“少了一段”。
试想上述情况中N=5，就不会发生这种情况，每一个值出现的概率都是2/10。</p>

<p>为了解决这个问题，思路是这样的：假设rand()的返回值范围是[0, M)，我们需要在这个范围划分出N个bucket，然后随机一个数，看这个数落到哪个bucket里，那么就返回这个bucket的标号。每份的bucket的长度L为M/N，那么这个范围中最后还剩余M%N。
如果rand() &lt; M - M%N，那么就返回该值/ L；否则就重试一遍，直到达到上述条件。</p>

<p>用C++写出来代码是这样的：
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>typedef unsigned long long ull
</span><span class='line'>ull bucket_size = M/N;
</span><span class='line'>ull remain = M%N;
</span><span class='line'>ull r;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;do {
</span><span class='line'>    r = rand();
</span><span class='line'>} while (r &gt;= M - remain);&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;return r/bucket_size;</span></code></pre></td></tr></table></div></figure>
这样返回值就是满足在[0,N-1]上的均匀分布。</p>

<p>另外，想到了一道面试题：函数rand5可以返回在[1,5]上的一个随机数，满足均匀分布，如何用这个rand5来实现一个rand7（即可以返回[1,7]上的一个随机数）？这个题的本质和上述思想是一致的，读者诸君不妨想想如何求解。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[无锁是万能药吗]]></title>
    <link href="http://zyearn.github.io/blog/2016/12/20/lock-vs-lockfree/"/>
    <updated>2016-12-20T21:17:00+01:00</updated>
    <id>http://zyearn.github.io/blog/2016/12/20/lock-vs-lockfree</id>
    <content type="html"><![CDATA[<p>经常会听到有人这样说，把某个地方的锁换成了无锁（lockfree）以后，性能提高了多少多少倍。
不禁会让人产生疑问：是不是只要有锁的地方，换成lockfree后都可以提高性能呢？</p>

<p>答案是具体情况需具体分析。</p>

<p>一部分朋友觉得用锁会影响性能，其实锁指令本身很简单，影响性能的是锁争用（Lock Contention<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>），导致scalability非常差<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>。什么叫锁争用，就是两个线程都想进入临界区，但只能有一个线程能进去，这样就影响了并发度。有兴趣的朋友可以去看看glibc中pthread_mutex_lock的源码实现，在没有contention的时候，就是一条CAS指令，内核都没有陷入；在contention发生的时候，选择陷入内核然后睡觉，等待某个线程unlock后唤醒（详见<a href="https://en.wikipedia.org/wiki/Futex">Futex</a>）。</p>

<p>“只有一个线程在临界区”这件事对lockfree也是成立的，只不过所有线程都可以进临界区，最后只有一个线程可以make progress，其它线程再做一遍。</p>

<p>所以contention在有锁和无锁编程中都是存在的，那为什么无锁有些时候会比有锁更快？他们的不同体现在拿不到锁的态度：有锁的情况就是睡觉，无锁的情况就不断spin。睡觉这个动作会陷入内核，发生context switch，这个是有开销的，但是这个开销能有多大<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>呢，当你的临界区很小的时候，这个开销的比重就非常大。这也是为什么临界区很小的时候，换成lockfree性能通常会提高很多的原因。</p>

<p>再来看lockfree的spin<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>，一般都遵循一个固定的格式：先把一个不变的值X存到某个局部变量A里，然后做一些计算，计算/生成一个新的对象，然后做一个CAS操作，判断A和X还是不是相等的，如果是，那么这次CAS就算成功了，否则再来一遍。如果上面这个loop里面“计算/生成一个新的对象”非常耗时并且contention很严重，那么lockfree性能有时会比mutex差。另外lockfree不断地spin引起的CPU同步cacheline的开销也比mutex版本的大。</p>

<p>lockfree的意义不在于绝对的高性能，它比mutex的优点是使用lockfree可以避免死锁/活锁，优先级翻转等问题。但是因为ABA problem、memory order<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>等问题，使得lockfree比mutex难实现得多。</p>

<p>除非性能瓶颈已经确定，否则还是乖乖用mutex+condvar，等到以后出bug了就知道mutex的好了。如果一定要换lockfree，请一定要先profile，profile，profile！确保时间花在刀刃上。</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>http://preshing.com/20111118/locks-arent-slow-lock-contention-is/<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>A classic paper on how different locking alternatives do and don’t scale: “The Performance of Spin Lock Alternatives for Shared-Memory Multiprocessors”<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>context switch的开销不仅仅是push和pop寄存器，它还引发了cache、TLB、branch predictor等CPU状态的丢失，具体如何测量CS的值，请参考“lmbench: Portable tools for performance analysis”<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>有同学问无锁和自旋锁有什么区别，不都是在一个循环里spin吗？自旋锁的本质还是应用层的锁，当一个线程持有锁后，被调度出去了，其它线程还是无法继续，而lockfree不是这样的，它可以保证至少一个线程make progress<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>关于memory order，这是个不错的入门资料：http://www.chongh.wiki/categories/High-performance/<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[推荐一门课：6.828]]></title>
    <link href="http://zyearn.github.io/blog/2016/02/24/recommmend-6-dot-828/"/>
    <updated>2016-02-24T20:19:00+01:00</updated>
    <id>http://zyearn.github.io/blog/2016/02/24/recommmend-6-dot-828</id>
    <content type="html"><![CDATA[<p>这篇博文的目的是向大家推荐一门课：MIT的<a href="https://pdos.csail.mit.edu/6.828/2014/index.html">6.828</a>。</p>

<p>这门课主要讲的是操作系统原理与实践，具体分三个部分：lectures，labs and readings。
Lectures部分会通过介绍xv6来阐述OS原理，并解读xv6源码；
Labs是这门课的实践部分，课程会提供一个OS的框架，但核心部分全部都是缺失的，需要学生来填写核心代码来实现这个OS；
Readings部分会阅读一些paper来了解一些更深入、更有意思的topic。</p>

<!-- more -->


<p>一个很自然的问题是，它与别的OS课程的区别在哪里？
最大的一个区别是，这门课的实践部分比重非常非常大，而OS本身就是一个实践学科，所以6.828的编程练习会让你对OS的概念非常清楚。
具体来说，这门课一共有7个lab，写完这7个lab，一个操作系统就被写出来了（名字叫JOS，是专门为这门课设计的Exokernel，麻雀虽小五脏俱全），除此之外，老师们为了让学生了解不同OS的架构和风格，在讲课阶段会主要以xv6（一个教学的操作系统，它是Monolithic kernel）的代码讲解OS概念，也就是说，在学期末，你会自己编写一个Exokernel和完整阅读一个Monolithic kernel的代码。</p>

<p>虽然我本科阶段也上过OS，但大作业的量完全没有到达这个编码强度（当时交大的OS课大作业是编写一个toy文件系统），导致自己以前对很多OS的概念和实现细节都是只见树木不见森林。然后从去年12月初，一共用了三个月的时间把这门课刷完了，对OS的理解清楚了很多，以及本科学的很多知识点都串了起来。</p>

<p>基于这个原因，不管你是学生还是已经工作几年的前辈，如果你想了解一个小型OS具体到代码是如何实现的，这门课是首选。</p>

<p>介绍一下每个Lab的需要做的事情：</p>

<ul>
<li><p>Lab1是熟悉的过程，需要学习QEMU模拟器的使用、开机启动流程、调试工具、bootloader、以及整个加载kernel的流程。做完这个lab会具备基本的内核调试能力，以及掌握开机到通电，bootloader是如何加载kernel的。</p></li>
<li><p>Lab2要完成JOS的的内存管理模块，需要学习一些计算机基础知识，如虚拟地址系统是如何工作的，地址空间是如何切分的，物理页面是如何管理的。做完这个lab将会给JOS添加最基本的内存管理功能，即Kernel其余模块需要物理页，这个模块可以分配出来。</p></li>
<li><p>Lab3为JOS添加进程的支持、异常/中断的支持、系统调用和页中断的支持。这个lab内容比较多，但收获也比较大，做完后会对从用户态陷入内核态，执行系统调用，然后返回这整个流程都非常清楚（不是泛泛的清楚，而是代码级别的清楚，这是和学概念不同的地方）。</p></li>
<li><p>Lab4为JOS添加多核支持、RR调度、COW的fork、抢占式内核、时钟中断和最基本的IPC机制。做完Lab3和Lab4，一个能用的OS已经出来了，但用途非常有限，因为没有文件系统和网络的支持，Lab5和Lab6就会做这两件事情。</p></li>
<li><p>Lab5为JOS添加基于Disk的文件系统、块缓存、实现键盘中断、修改一个shell支持最基本的功能。完成这个Lab后就可以在shell里面输入命令以及文件系统的支持了。JOS没有实现crash recovery，在xv6用log的方式实现了crash recovery，代码都非常好（虽然效率很差&hellip;课里会讲）。</p></li>
<li><p>Lab6为JOS添加网络的支持。网络部分主要分两个大块，一个是协议栈的编写，一个是驱动的编写。协议栈太复杂了，于是课程提供了现有的lwip库。我们需要实现驱动，这涉及到阅读intel的网卡硬件手册，这是本课程让人头痛的地方之一。完成驱动以后，需要完成用户态的network server（网络服务以用户进程的形式提供是Exokernel的特点之一，和Microkernel很像），还需要完成一个用户态的web server，完成之后经过QEMU的端口转发，在host机器可以访问qemu里面运行虚拟机的web server！第一次运行成功也是觉得非常神奇，因为OS从上到下，在此时此刻，全部打通了，可以向外提供服务了，并且这个OS的核心代码全部是在课程里完成的。</p></li>
<li><p>Lab7和Lab6只需要选择一个做，Lab7是一个需要组队的开放式课题。</p></li>
</ul>


<p>不可否认的是有些lab真的非常让人头痛、一个bug可能会调很久甚至几天没有进展，但到最后收获的远多于付出。</p>

<p>如果你对上面的Lab有兴趣，那花三个月去上一下这门课会非常值。其实可能用不上三个月，我是跟着课程进度一点点做的，如果有一点OS基础可以直接做Lab，稍微加班加点一个月左右也可以完成了。</p>

<p>JOS还有很大的提升空间，归根结底这只一个“working”OS，离工业级使用还差很多，以下是我总结的一些改进点：</p>

<ol>
<li><p>JOS和xv6的内存管理方式都是空闲链表，这导致如果内核想要连续的物理内存，将十分困难（因为碎片的存在，即使没有碎片，也将是O(n)的复杂度），所以linux采用了buddy system来解决碎片问题。（至于内核为什么需要连续的物理内存，请看我在V2EX上问网友的一个<a href="http://v2ex.com/t/256450">问题</a>）</p></li>
<li><p>JOS和xv6的进程调度是最简单的RR方式，这使得它们无法应用在某些特殊的场景下，而且父进程很容易fork子进程把CPU时间全抢了。</p></li>
<li><p>JOS和xv6根本就没有磁盘调度算法，应用层来一个读写磁盘请求就直接由驱动发送给磁盘控制器。</p></li>
<li><p>JOS的文件系统效率差，且不支持crash recovery，即使是实现了crash recovery的xv6，效率也非常差。不过在文件系统设计中，performance（don&rsquo;t write the disk）和safety（write the disk ASAP）本身就是一个tradeoff。</p></li>
<li><p>&hellip;</p></li>
</ol>


<p>上完这门课后推荐看一下Rober Love的《Linux内核设计与实现》，会发现JOS到底哪里做得不好以及Linux是如何解决的。</p>

<p>附：Lab的<a href="https://github.com/zyearn/6.828-labs">代码地址</a>和上这门课时的一些<a href="https://github.com/zyearn/6.828-labs/blob/lab6/LabNotes">笔记</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[参加饿了么编程马拉松感]]></title>
    <link href="http://zyearn.github.io/blog/2015/12/02/eleme-hackathon/"/>
    <updated>2015-12-02T14:30:00+01:00</updated>
    <id>http://zyearn.github.io/blog/2015/12/02/eleme-hackathon</id>
    <content type="html"><![CDATA[<p>饿了么在今年十一月的时候举办了一个黑客马拉松，官方主页在<a href="http://hackathon.ele.me/">这里</a>，看了简介以后我认为有两点比较吸引人。</p>

<p>首先，比赛形式比较新颖，之前也参加过类似的马拉松以及听闻过很多XX编程马拉松，形式都是差不多的：接受组队报名，然后花上两天时间大家待在一个地方通宵编程实现一个和主办方做的事完全没有关系的创意，一般会在第二天下午开始做presentation，最后会根据评委打分决出获胜队伍。这种类型的比赛，根据我的观察，presentation是最重要的，其次是idea，最后才是技术。<!-- more -->而这次的饿了么举办的马拉松分初赛和决赛，初赛前10名进入决赛，初赛需要实现一个功能，最后评测完全靠的是实力和技术，分数公开透明。虽然还不知道决赛题目是什么，但也令人期待。</p>

<p>其次，如果真的进了前10名，能去参加决赛，大家可能都是非常强的高手，想想也令人激动不是么。</p>

<p>于是和另外两位小伙伴一起参加了这次初赛。</p>

<h2>题目描述</h2>

<p>初赛的题目是使用Python, Java, Go三种语言（任选其一）实现一个“限时抢购”功能。具体来说，就是实现一个web服务，对外提供一个restful接口，让模拟用户可以通过接口来抢购数据库中的食物。评分使用功能测试、性能测试的结果做为指标。功能测试就是看有没有超售，错误处理之类的，通过了功能测试才能进入性能测试这个打分的环节。</p>

<h3>性能测试</h3>

<ol>
<li>给定 100 个食物，每个库存 1000</li>
<li>脚本模拟 1000 个并发用户同时进行抢单。（登录 -> 查看食物列表 -> 随机选择 1-3 个食物购买 -> 下单）</li>
<li>将按照“成功下单数/秒”的峰值进行排名</li>
</ol>


<h3>测试环境</h3>

<ol>
<li>2CPU-4GB 服务器 * 3，运行应用。（请求会随机分布到 3 台服务器上）</li>
<li>2CPU-4GB 服务器 * 1，提供 redis</li>
<li>25GB 1000qps 腾讯云数据库，提供 mysql</li>
<li>12CPU-12GB 服务器 * 1，运行性能测试脚本</li>
</ol>


<p>一个能跑的程序还是很容易实现的。其中有一个难点是，因为是分布式服务，所以我们必须保证下单并减库存的操作是原子的，传统的读-改-写在高并发情况下不适用，好在redis支持lua脚本是原子的，于是这个问题就解决了。</p>

<h2>数据库设计</h2>

<p>因为提供了redis，又是性能的比赛，所以我们决定放弃mysql，完全用redis来做。</p>

<p>因为负载均衡的存在用户请求可能被分发到任何一台应用服务器上，redis中需要存储一些共享的数据，如用户登录后的token，用户的购物车，用户的订单，以及最重要的食物库存，如下图所示：</p>

<pre><code>KEY                             VALUE
---------------------------------------------------------
token:user                      hashmap: {&lt;tokenid&gt;: &lt;userid&gt;}  // 检测token的合法性
user:order                      hashmap: {&lt;userid&gt;: &lt;orderid&gt;}  // 获取某个user的订单，系统只允许一个用户下一单，所以这个hashmap能检测是否重复下单
cart:user                       hashmap: {&lt;cartid&gt;: &lt;userid&gt;}   // 获取购物车是哪个user的
cart:&lt;cartid&gt;                   hashmap: {&lt;foodid&gt;: &lt;cnt&gt; }     // 该购物车的食物及数量
order:user                      hashmap: {&lt;orderid&gt;: &lt;userid&gt;}  // 这个order对应哪个user
order:&lt;orderid&gt;                 hashmap: {&lt;foodid&gt;: &lt;cnt&gt; }     // 每一个订单包含的食物及数量
food:stock                      hashmap: {&lt;foodid&gt;: &lt;stock&gt;}    // 食物的库存
</code></pre>

<h2>框架的选择</h2>

<p>一开始我们用python写了个能跑过测试的版本，能异步的地方都用了协程，但是分数还是比前十的队伍差了很多，于是我们怀疑是不是语言层面的问题导致了分数差那么多，于是我们队伍的小伙伴对python和go做了一个性能比较，其中每一次访问<code>/</code>都会使redis调用一个脚本，这个脚本和我们下单的操作运算量差不多，结果如下：</p>

<pre><code>LANG    WEB         REDIS             METHOD      TIME
---------------------------------------------------------
python  tornado     redis-py          coroutine   1.406ms
python  tornado     redis-py          sync        1.022ms
python  aiohttp     asyncio-redis     coroutine   0.879ms
python  falcon      redis-py          gunicorn    0.669ms
node    express.js  node-redis        event       0.301ms
golang  net/http    gopkg.in/redis.v3 coroutine   0.245ms
</code></pre>

<p>我们发现在相同的环境下，go的性能是最好，虽然很不情愿，但不得不放弃python用go重写。事实证明，用go以后分数有明显上升。</p>

<h2>实现</h2>

<p>食物的库存存在redis的hashmap中(foodid映射到stock)，下单用lua脚本来做，查询库存就返回所有食物列表和相应库存。后来我们发现这个方法效率太低，每次查询库存都要返回所有的食物，即使很多食物库存都没有变化过，太浪费I/O。于是我们小伙伴提出了一个基于timestamp的方法，结果就是每次查询库存值传输某个时间之后变化的食物，大大减少了流量。</p>

<p>具体方法是这样做的：本地存储一个当前timestamp，并且redis端存储一个foodid到该食物最后更新时间，然后把(更新时间|foodid|foodstock)这个长整型存储在redis中的ordered set里，key就是更新时间，于是我们在查询库存的时候，只需查询从app的timestamp到正无穷的时间里有哪些元素就可以了，复杂度是log(N)的，然后根据这些元素的值就可以还原出id和stock值。</p>

<p>这是个非常精妙的思想，当时在腾讯实习的时候看过微信内部的一篇文章，说微信为了同步不同设备上的消息记录，用的就是这个时间戳的思想，差分传输而非全部。</p>

<p>下单操作就麻烦一些了，先根据id找到这个食物的最后更新时间，然后根据这个值从ordered set里拿到(更新时间|foodid|foodstock)这个长整型，分解出id和stock，减完库存还得删除原来的元素插入新的元素，这些都是log(N)的操作。</p>

<h2>突破</h2>

<p>随着比赛的进行，我们发现自己的分数卡在一个瓶颈了。某一天晚上我突然发现，我们实现了系统的强一致性，而题目里根本没有要求我们这么做！我们用timestamp的目的是为了让查询库存节省流量，但是带来的tradeoff是每次下单的时候都有好几次log(N)操作（需要根据查询食物最后更新时间来找到这个食物的库存，而后者存在redis的ordered set里）。但是在测试的时候根本就没有测获得库存的强一致性，题目要求的是最终一致性，所以我们没必要实现地那么老实，只要一个goroutine隔个两秒去redis拉一下数据就可以了，然后我们的下单操作变得异常简单，把stock存成hashmap，只是几个简单的O(1)操作。</p>

<p>我们为了库存显示的强一致而牺牲了下单的效率，这明显是不值得的，我们宁愿下单快，但库存会有一些误差。这在实际工程也是合理的，网站显示库存还剩一个，但是你下单的时候发现库存为0，这是用户可以理解的，手慢了就被别人买掉了。但是这个妥协大大带来了下单峰值的上升。</p>

<h2>优化</h2>

<p>整个比赛后期就是在不断优化的过程中，其中一个比较难的地方在于如何确定瓶颈，在redis？在I/O？还是在APP服务器的处理速度？最后几天就是在不断地对程序做profile然后性能优化然后再做profile。一个印象比较深的例子是有一个操作我在不断纠结要不要放到redis的lua脚本去做，如果放了会增加redis的负载，但是会减少网络I/O的时间，线上测出来的结果又是差不多的，那这个做还是不做？在比如reids线程池到底搞多少个才是合适的？</p>

<p>另外，把能缓存的数据全部缓存起来，性能会提高不少。</p>

<h2>TradeOff</h2>

<p>做这个项目中遇到了太多需要tradeoff的地方：</p>

<ol>
<li>代码的可读性和性能，为了提高性能我们牺牲了很多可读性</li>
<li>不要用第三方库，虽然手写一些功能会比较累、易出错，但有些第三方库为了通用性，使得效率大大下降。我们把使用的一些第三方库都删掉以后，效率又提高了不少</li>
<li>下单一定要快，这样每秒的单数就增加了，而实时显示库存就显得不那么重要</li>
<li>用户注册返回的token如何生成得高效且具有随机性</li>
<li>将Go程序设置为多核后，对共享变量的读取用乐观锁还是悲观锁</li>
</ol>


<h2>代码</h2>

<p>放在了<a href="https://github.com/zyearn/eleme-hackathon">github</a>上。</p>

<p>我们的代码峰值是4600多单每秒，而饿了么大学（好像是内部员工组成的队伍）的实现是5000多单每秒，还是有400的差距。</p>

<h2>感想</h2>

<ul>
<li>队友很重要，两个小伙伴很给力（<a href="https://abcdabcd987.com/">乐群</a>和<a href="http://www.zhihu.com/people/lz1996">骆神</a>）</li>
<li>Go好简洁，很好用</li>
<li>做系统考虑好TradeOff很重要</li>
<li>redis好强大，单线程事件驱动网络I/O的典范</li>
<li>这是一个优化比赛，看谁能优化到极致</li>
</ul>


<h2>彩蛋</h2>

<p>在看了饿了么5000分的标准实现后，发现这400分的差距还是有原因的，为了性能redis里面存的越少越少，这样I/O次数就少，罗列一些我们组没有注意到的点：</p>

<ul>
<li><p>token其实是不需要存redis的，token如果是userinfo的一个函数映射，那么每台机器都可以根据这个函数事先为每个user生成一个token，而不是随机字符串。比如md5(userId)作为token，然后在起服务器的时候就把token生成好，并且维护一个token到userinfo的映射（为了之后带token的请求找到该user），就完全不需要redis了。这样做虽然好，但token好像无法过期了？于是我问了一下主办方，给我发了一篇<a href="http://lucumr.pocoo.org/2013/11/17/my-favorite-database/">文章</a>，思路非常好，把client当做database，这样本地就根本不用存一个用户相关的数据，比如token。虽然这篇文章表明了token可以不用存储，但没有回答token的生成和userinfo相关到底是不是一个好的选择？在我们的实现里，用了随机字符串来作为token，每次都是on-the-fly生成，效率明显会差一点</p></li>
<li><p>为了判断user是否只下了一单，在我们实现里用了user:order这个hashmap。官方没有这个数据结构，只维护了order存了哪些food和count（也是个hashmap），然后每个user的order被命名为<code>o_&lt;userId&gt;</code>，所以只要用<code>EXIST</code>命令看一下这个key存不存在就知道用户有没有重复下单了</p></li>
<li><p>把userId嵌到购物车Id里面，那么reids就不用存购物车Id到userId的映射了（值得吐槽的是判定购物车Id是不是有效的方法是传来的string是否满足他事先规定的pattern，这在现实中完全不能用啊）</p></li>
<li><p>我们的实现里下单时把购物车这个hashmap完整地复制到了订单这个hashmap，而官方只用了一条redis命令<code>RENAME</code></p></li>
<li><p>官方实现里，每个用户下单的orderId竟然是事先生成好的，其值就等于userId，难道这个不应该是on-the-fly生成的么，这样的好处是下单返回成功和上述的<code>RENAME</code>可以异步执行，这样的设计使得我们设计中的order:user成为累赘了，因为userId本身就是orderId，根本就不用这个查找</p></li>
<li><p>在官方实现里是怎么查询所有订单的呢？因为订单都是以<code>o_</code>开头的，所以用redis的命令<code>KEYS o_*</code>就可以获取所有以<code>o_</code>开头的key，那么所有订单也自然就拿到了，这里需要(1+n)次（1次查询所有订单名字+根据返回的名字查询n个订单的详细内容）redis访问，但查询订单不在benchmark里，所以实现得耗时一些没有影响</p></li>
<li><p>官方用了go-reuseport这个库，即多进程端口复用，据说比单进程端口要性能好一些</p></li>
<li><p>官方把go的GC关掉了，据说效果不大，在我们的profile结果里GC也只占了很小一部分</p></li>
</ul>


<p>结论就是，虽然官方实现有几点值得吐槽的地方（比如判定作弊的标准不太明确，导致可能有些选手即使想到了优化方法，然后觉得这个实际中不能用，就放弃了），为了性能牺牲掉了很多实用性（比如官方Go的实现没有可拓展性，假如来了一个需求说一个用户可以下多个订单，就要大改了），毕竟是个性能比赛。但确实有很多地方值得学习，根据这个特定的场景，redis数据库设计得非常简洁，大大减少了I/O次数（瓶颈），而且用了许多redis技巧和Go技巧，特别是发出异步redis请求的goroutine和channel的使用，对于初学Go的我帮助很大。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何用C/C++写一个基于事件的爬虫]]></title>
    <link href="http://zyearn.github.io/blog/2015/09/09/how-to-write-a-event-based-crawler-using-c/"/>
    <updated>2015-09-09T20:52:00+02:00</updated>
    <id>http://zyearn.github.io/blog/2015/09/09/how-to-write-a-event-based-crawler-using-c</id>
    <content type="html"><![CDATA[<p>在去年三月份的时候，写过一篇<a href="http://zyearn.github.io/blog/2014/03/08/zhihu-spider/">文章</a>，讲了一下如何写一个知乎爬虫，爬下最高票的答案，并且把代码放到了<a href="https://github.com/zyearn/zhihuCrawler">github</a>。在这一年多的时间里，前前后后有很多人来问我关于这个爬虫的一些实现细节，在回答他们的同时发现自己原来的代码真是写得太烂了，最近正好有空，把代码和架构都重写了一下，不能再误人子弟了。</p>

<!-- more -->


<p>所以有了这篇文章，记录下自己的一些改进，以及尽可能说清楚如何用C++实现一个高性能爬虫。</p>

<h2>为什么要用C++写</h2>

<p>在继续往下看之前一定要先想清楚一个问题，现在用Python或者NodeJS可以非常快速地开发出一个爬虫，库齐全，开发成本非常低，那为什么还要用C来写爬虫？答案是这要看你的目的。如果你单纯是为了完成一个数据抓取的任务，当然是任务完成得越快越好，以后代码越好修改越好，首选就是那些库齐全的动态语言，但如果你的目的是为了理解底层系统，理解抓取数据的每一个环节，那么我的推荐是用C++写吧，并且所有轮子都自己造。我的目的是后者，所以选择了用C来写。既然所有轮子都自己造了，那这篇文章应该叫，如何不用任何第三方库，只用C/C++内建函数来完成一个网络爬虫。</p>

<p>用Python写会是什么样子？有Requests库来封装HTTP请求，有BeautifulSoup来解析HTML，大大减少了开发难度，你只需要知道爬虫的一般流程，很容易写出一个能跑的代码，用NodeJS也是一样的。</p>

<h2>知乎爬虫原理</h2>

<p>如果有读者不太清楚爬虫的原理，请先看一下这篇<a href="http://www.zhihu.com/question/20899988">入门文章</a>。</p>

<p>接下来简单说一个我的zhihu爬虫的原理，因为我的目标是爬下最高赞/最高关注这些类型的答案和问题，所以从用户主页出发是最好不过的，比如从用户主页点击“回答”，就可以看到用户的所有回答，然后抓下来，点击“提问”，就可以看到用户所有的提问。把所有用户的所有回答/提问都抓下来然后根据点赞数/关注数排序，就是我想要的结果。那所有用户怎么得到？从一个用户出发（即队列中的初始URL），把TA的所有关注的人和关注者都爬下来，不重复地放入URL队列中，等到当前用户处理完，再从URL队列里拿下一个用户，如此循环即可。</p>

<p>仔细想想，这个方法会有一个问题，如果一个人即不关注别人也不被别人关注，且不在初始URL队列中，那么这个用户的回答和提问永远不会被抓到。更一般的结论是，如果有用户群构成“孤岛”，那么这些用户群都不会被爬虫访问。举个例子，A、B互相关注，C、D互相关注，如果我们将A放入初始URL队列，那么爬虫只可能抓下A、B的数据，因为C、D构成了“孤岛”，怎么解决这个问题？</p>

<p>再想想，这个问题真的有必要解决吗？这个问题会对我们造成困扰的情况是，一个大V答了一个赞数很高的问题，但是TA竟然在某座“孤岛”上，如果我们称大部分人所构成的连通图叫主图，那么这个大V构成的“孤岛”和主图上的人一点关系都没有，即不被关注也不关注别人，这几乎是不可能的事情，所以这个问题不需要解决。</p>

<h2>如何用C++写爬虫</h2>

<p>无论用Python或者C++写爬虫，底层都是一样的，都是和server建立若干个TCP连接，然后把HTTP请求写入这个TCP socket中，等待server的数据返回。为了高效处理I/O，在linux平台下需要用epoll（别的平台请用各自的机制）。</p>

<p>所以一个C++爬虫步骤大概是这样的，本质上就是一个事件循环（event loop）：</p>

<ol>
<li><p>初始化epoll，并和server建立TCP连接</p></li>
<li><p>从URL队列中拿出url，并准备好http请求</p></li>
<li><p>将http请求写入到这个TCP socket中，并把这个socket加入epoll中</p></li>
<li><p>检查活动事件（epoll_wait）</p></li>
<li><p>处理事件，读取HTML，解析HTML，处理HTML，然后把相关未处理过的URL放入URL队列中</p></li>
<li><p>回到第2步</p></li>
</ol>


<h2>原来的代码结构</h2>

<p>先简单描述一下去年写的爬虫代码是怎么误人子弟的。</p>

<p>程序从队列里拿到一个URL后，需要去下载这个URL的页面，解析出我需要的数据，然后把它的下一层URL加入队列中。原来的爬虫代码就老老实实地实现了这个步骤，阻塞地等待页面下载完成，再去处理这个页面。其实这是很低效的，因为阻塞的这段时期我们什么都干不了，浪费了带宽。为什么不把队列里的其它URL请求一起发出去呢，然后有数据来了我就处理。这就是为什么爬虫为什么要用基于事件来写的原因。</p>

<p>这里需要理解爬虫这种程序的本质，它是网络I/O密集程序，不是CPU密集，而处理I/O密集最高效的做法就是事件循环。</p>

<p>所以我做的一个做大的改善就是把原来的阻塞爬虫改成了基于事件的爬虫，它得到的好处是可以完全把带宽跑满，爬取速度最大化。</p>

<p>除此之外，还有一个改善是把多线程模型改成了单进程模型。有同学可能会产生疑惑，难道利用多核还会比单核性能差？我们从以下两点来分析：</p>

<ol>
<li><p>根据amdahl定律，对系统中一个模块的加速，不仅取决于加速比，还取决于这个模块在原来系统中占的比例。爬虫是I/O密集程序，绝大部分时间都花在了网络I/O上，CPU大部分时间是空闲的，所以提高CPU的利用率其实效果很小。</p></li>
<li><p>多线程会引入额外的开销，最大的开销可能就是锁了。比如你要把新的URL加入队列，这时候在多线程环境下肯定要对队列加锁。</p></li>
</ol>


<p>那么问题就是，第一点所带来的性能提升和第二点所带来的开销，哪个更大一点？如果第二点大，我们果断要换成单进程。答案是看环境，我们极端点看，如果你的带宽无穷大，网络情况无穷好，那么请求一发出去立刻就回复了，这个网络I/O密集程序硬生生变成了CPU密集，多线程会好；如果你的带宽无穷小，那么锁带来的开销会占比更大，一个任务来了多线程之间还要竞争一下，单线程就直接处理了且没有锁的性能开销，用单线程会好。我们需要在不同的环境下选择最好的办法，不过一般来说，现实中最大的时间开销一定在网络I/O。</p>

<h2>用C++实现爬虫时的难点</h2>

<ol>
<li><p>从TCP socket读取数据到把完整的HTML数据交付上层需要一个数据层，因为如果调用read返回<a href="http://stackoverflow.com/questions/4058368/what-does-eagain-mean">EAGAIN</a>时，这时是不知道到底有没有接受到完整的HTML，需要保存好当前读到的网页内容，并通过一个状态机来解析当前收到的数据，保存当前的状态，如果解析完成（读到全部数据了）就返回SUCCESS，否则就就返回ERROR，等待下一次数据来临，继续解析状态机。用动态语言不需要考虑这一点，会直接传递给用户层完整的数据。</p></li>
<li><p>请求得太快，知乎会返回429错误（即提示客户请求太多，稍后再试），这个问题怎么解决？乖乖地等待一段时间再去抓是一种浪费带宽的行为。服务器判断请求太多是看这个IP在一段时间的请求数太多了，如果我们IP分散为N个不同IP，那就解决这个问题了。这个方案叫动态IP或者代理IP。那么多IP意味着要花很多的钱，如果不愿意花钱，还是乖乖等一段时间再发请求吧。</p></li>
<li><p>爬虫里一个需求，要获得一个用户的所有关注的人和关注者，但这些东西都是通过ajax获取的，所以要写一个post请求来模拟ajax。其中post data里有一个hash_id和_xsrf，这两个值都在哪里可以获得？后来在该用户的主页的HTML里找到了这两个值。</p></li>
<li><p>怎么用C++解析HTML？比如上面一点提到的，我要找到这个页面里的hash_id，它可能是某个HTML元素的属性，怎么得到这个属性值？用过JQuery的同学这时会想，如果C++里面也有一个像JQuery那么好用的库该多好，直接写个选择器就获得属性的值了。我简单地调研了一下，C++还是有这样的库的。基于学习的目的，最好自己写一个这样的库，所以，问题来了，怎么实现一个HTML parser？或者更简单的，怎么实现一个正则匹配？</p></li>
<li><p>如何管理一个请求的周期，因为一个请求的周期中，状态太多了。为什么状态多，因为一个请求会涉及很多异步操作，首先获取该用户的答案页面，这时候要等待server的回复，处理完以后获得改用户所有关注的人和关注者的页面，也要等待server的回复，再把这些所有用户加入队列后，这个请求周期才算结束。</p></li>
<li><p>需要自己处理一些HTTP header的细节。比如不希望接受到HTTP response header里Transfer Encoding: chuncked回复，因为它显然没有Content-length直接获取到数据长度来得方便，该怎么办？再比如不希望接受到gzip处理过的数据，希望收到plain text，又该怎么办？</p></li>
<li><p>架构怎么设计。首先最底层是TCP层，上层应该封装一个数据接收层，再上层应该是HTML解析层，最后是事件循环层。这些层次/模块怎么做到耦合度最低？</p></li>
<li><p>网络异常怎么处理，比如read返回error（eg  Connection reset by peer），或者EOF。EOF需要重新建立一个新的连接，然后继续前一个请求（或者说继续状态机）。</p></li>
</ol>


<h2>用C++相比Python，NodeJS的优点</h2>

<ol>
<li><p>系统的掌控性。比如我们希望TCP连接数要控制在1000，完全可能很容易地实现。并且可以知道哪里会耗内存、CPU，底层在发生什么我们更容易知道。比如，在HTTP request header里写上<code>Connection: keep-alive</code>可以让很多请求复用一个TCP连接，在用C++实现的时候，对应的实现方法很简单粗暴：从socket读完对方服务器发来的response后，再构造一个header发过去即可。</p></li>
<li><p>因为一些内建库的缺乏，并且出发点是学习，我们会重新造一些轮子，与此同时，提高了编程能力。
比如说读配置文件，格式是json，可以自己用C写个json parser。再比如上文提到的HTML parser，也可以用C写一个，还有基于epoll的事件循环，可以抽象成一个通用的网络库。有太多轮子可以造，要把其中任意一个轮子写好都是非常难的事情。</p></li>
<li><p>高性能。可能由于网络的大延迟使得这个优点不那么明显。</p></li>
</ol>


<h2>总结</h2>

<p>本文基于我一年多之前写的zhihu爬虫以及最近的大规模改进，总结了如何用C++编写的高效、基于事件驱动的知乎爬虫，同时也列出了用C++写爬虫时的一些难点与收获。</p>

<p>如果你有兴趣看看竟然有人用C++写了一个爬虫究竟是什么样子的，代码在<a href="https://github.com/zyearn/zhihuCrawler">这里</a>。</p>
]]></content>
  </entry>
  
</feed>
